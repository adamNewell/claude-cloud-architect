[
  {
    "id": "MLCOST01-BP01",
    "title_full": "MLCOST01-BP01 Use managed spot training for cost-effective model training",
    "title": "Use managed spot training for cost-effective model training",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html",
    "description": "Use SageMaker Managed Spot Training to reduce training costs by up to 90 percent. Enable checkpointing to resume training if spot instances are interrupted. Design training jobs to be checkpoint-friendly with appropriate checkpoint intervals.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Training cost optimization"],
    "relatedIds": ["COST05-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST01-BP02",
    "title_full": "MLCOST01-BP02 Right-size training instances based on workload requirements",
    "title": "Right-size training instances based on workload requirements",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html",
    "description": "Analyze training job resource utilization to identify right-sizing opportunities. Use SageMaker Debugger to monitor GPU, CPU, and memory utilization during training. Start with smaller instances and scale up only when resource bottlenecks are identified.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Training cost optimization"],
    "relatedIds": ["COST05-BP02"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST01-BP03",
    "title_full": "MLCOST01-BP03 Implement early stopping to reduce unnecessary training",
    "title": "Implement early stopping to reduce unnecessary training",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-01.html",
    "description": "Configure early stopping conditions to terminate training jobs when model performance plateaus. Use validation metrics to detect overfitting early. Set maximum training time limits to prevent runaway training costs.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Training cost optimization"],
    "relatedIds": ["COST05-BP03"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST02-BP01",
    "title_full": "MLCOST02-BP01 Right-size inference endpoints based on traffic patterns",
    "title": "Right-size inference endpoints based on traffic patterns",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html",
    "description": "Analyze inference traffic patterns to select appropriate instance types and counts. Use CloudWatch metrics to monitor endpoint utilization and identify over-provisioned resources. Implement auto scaling with appropriate minimum and maximum instance counts.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Inference cost optimization"],
    "relatedIds": ["COST05-BP04"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST02-BP02",
    "title_full": "MLCOST02-BP02 Use serverless inference for intermittent workloads",
    "title": "Use serverless inference for intermittent workloads",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html",
    "description": "Deploy models using SageMaker Serverless Inference for workloads with infrequent or unpredictable traffic. Pay only for the compute time used during inference. Accept cold start latency tradeoffs for cost savings on low-utilization endpoints.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Inference cost optimization"],
    "relatedIds": ["COST05-BP05"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST02-BP03",
    "title_full": "MLCOST02-BP03 Use multi-model endpoints to consolidate inference resources",
    "title": "Use multi-model endpoints to consolidate inference resources",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html",
    "description": "Deploy multiple models on a single endpoint using SageMaker Multi-Model Endpoints to improve instance utilization. Implement model caching strategies to minimize model loading latency. Suitable for scenarios with many models that are not all accessed simultaneously.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Inference cost optimization"],
    "relatedIds": ["COST05-BP06"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST02-BP04",
    "title_full": "MLCOST02-BP04 Use AWS Inferentia for cost-effective inference at scale",
    "title": "Use AWS Inferentia for cost-effective inference at scale",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-02.html",
    "description": "Evaluate AWS Inferentia instances for inference workloads to achieve better price-performance compared to GPU instances. Compile models using SageMaker Neo for Inferentia. Suitable for high-throughput inference workloads with supported model architectures.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Inference cost optimization"],
    "relatedIds": ["COST05-BP07"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST03-BP01",
    "title_full": "MLCOST03-BP01 Implement data lifecycle policies for ML data",
    "title": "Implement data lifecycle policies for ML data",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-03.html",
    "description": "Configure S3 Lifecycle policies to transition training data and model artifacts to lower-cost storage tiers. Archive infrequently accessed historical data to S3 Glacier. Delete temporary training data and intermediate artifacts after defined retention periods.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Storage cost optimization"],
    "relatedIds": ["COST07-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST03-BP02",
    "title_full": "MLCOST03-BP02 Optimize storage for training datasets",
    "title": "Optimize storage for training datasets",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-03.html",
    "description": "Use efficient data formats and compression to reduce storage costs for training data. Store preprocessed data to avoid repeated transformation costs. Consider using S3 Intelligent-Tiering for datasets with varying access patterns.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Storage cost optimization"],
    "relatedIds": ["COST07-BP02"],
    "risk": "LOW",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST04-BP01",
    "title_full": "MLCOST04-BP01 Use SageMaker Savings Plans for predictable workloads",
    "title": "Use SageMaker Savings Plans for predictable workloads",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-04.html",
    "description": "Purchase SageMaker Savings Plans for consistent ML workloads to achieve significant cost savings compared to on-demand pricing. Analyze historical usage patterns to determine appropriate commitment levels. Combine with on-demand capacity for variable workloads.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Pricing optimization"],
    "relatedIds": ["COST06-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST04-BP02",
    "title_full": "MLCOST04-BP02 Monitor and allocate ML costs by project and team",
    "title": "Monitor and allocate ML costs by project and team",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-04.html",
    "description": "Implement cost allocation tags for ML resources to track spending by project, team, or environment. Use AWS Cost Explorer and Cost and Usage Reports to analyze ML spending patterns. Set up AWS Budgets to alert on unexpected cost increases.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Cost visibility"],
    "relatedIds": ["COST02-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLCOST04-BP03",
    "title_full": "MLCOST04-BP03 Implement resource cleanup automation for development environments",
    "title": "Implement resource cleanup automation for development environments",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlcost-04.html",
    "description": "Automate cleanup of unused ML resources including stopped notebook instances, orphaned endpoints, and completed training job artifacts. Implement scheduled shutdowns for development notebooks. Use lifecycle configurations to auto-stop idle resources.",
    "outcome": "",
    "pillar": "COST_OPTIMIZATION",
    "area": ["Cost visibility"],
    "relatedIds": ["COST03-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  }
]
