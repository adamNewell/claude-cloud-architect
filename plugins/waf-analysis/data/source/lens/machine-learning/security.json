[
  {
    "id": "MLSEC01-BP01",
    "title_full": "MLSEC01-BP01 Implement least privilege access for ML resources and data",
    "title": "Implement least privilege access for ML resources and data",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html",
    "description": "Apply the principle of least privilege to all ML resources including training jobs, endpoints, notebooks, and data stores. Use IAM roles with minimal required permissions for SageMaker execution roles. Implement separate roles for different ML lifecycle stages such as experimentation, training, and production inference.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Identity and access management"],
    "relatedIds": ["SEC03-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC01-BP02",
    "title_full": "MLSEC01-BP02 Secure access to training data and model artifacts",
    "title": "Secure access to training data and model artifacts",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html",
    "description": "Implement strict access controls for training datasets, feature stores, and model artifacts stored in Amazon S3. Use S3 bucket policies and IAM policies to restrict access. Enable S3 Object Lock for immutable storage of critical model versions and audit data access using AWS CloudTrail.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Identity and access management"],
    "relatedIds": ["SEC03-BP02"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC01-BP03",
    "title_full": "MLSEC01-BP03 Implement network isolation for ML workloads",
    "title": "Implement network isolation for ML workloads",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-01.html",
    "description": "Deploy ML training jobs and inference endpoints within VPCs to isolate them from public networks. Use VPC endpoints to access AWS services without internet exposure. Configure security groups to control inbound and outbound traffic for ML resources.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Network security"],
    "relatedIds": ["SEC05-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC02-BP01",
    "title_full": "MLSEC02-BP01 Encrypt training data and model artifacts at rest",
    "title": "Encrypt training data and model artifacts at rest",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-02.html",
    "description": "Enable encryption at rest for all ML data including training datasets, validation data, model artifacts, and inference logs. Use AWS KMS customer managed keys for encryption of S3 buckets, SageMaker notebooks, and EBS volumes attached to training instances.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Data protection"],
    "relatedIds": ["SEC08-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC02-BP02",
    "title_full": "MLSEC02-BP02 Encrypt data in transit for ML workloads",
    "title": "Encrypt data in transit for ML workloads",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-02.html",
    "description": "Enable encryption in transit for all ML communications including inter-container traffic during distributed training, API calls to inference endpoints, and data transfers to and from S3. Use TLS 1.2 or later for all connections and configure SageMaker to enable inter-container encryption.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Data protection"],
    "relatedIds": ["SEC09-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC02-BP03",
    "title_full": "MLSEC02-BP03 Implement data classification and handling procedures for ML data",
    "title": "Implement data classification and handling procedures for ML data",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-02.html",
    "description": "Classify training data and model outputs based on sensitivity levels. Implement appropriate handling procedures for personally identifiable information (PII) and sensitive data used in ML. Use Amazon Macie to discover and protect sensitive data in S3 buckets used for ML workloads.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Data protection"],
    "relatedIds": ["SEC07-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC03-BP01",
    "title_full": "MLSEC03-BP01 Validate and sanitize model inputs to prevent adversarial attacks",
    "title": "Validate and sanitize model inputs to prevent adversarial attacks",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-03.html",
    "description": "Implement input validation for inference requests to detect and reject malformed or potentially adversarial inputs. Define acceptable input ranges and formats based on training data distributions. Monitor for unusual input patterns that may indicate adversarial attack attempts.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Model security"],
    "relatedIds": ["SEC06-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC03-BP02",
    "title_full": "MLSEC03-BP02 Protect model artifacts from tampering and unauthorized access",
    "title": "Protect model artifacts from tampering and unauthorized access",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-03.html",
    "description": "Implement integrity checks for model artifacts to detect unauthorized modifications. Use cryptographic signatures to verify model authenticity before deployment. Store model artifacts with versioning and enable deletion protection for production models.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Model security"],
    "relatedIds": ["SEC08-BP02"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC04-BP01",
    "title_full": "MLSEC04-BP01 Implement comprehensive logging for ML operations",
    "title": "Implement comprehensive logging for ML operations",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-04.html",
    "description": "Enable detailed logging for all ML operations including training jobs, model deployments, and inference requests. Use CloudWatch Logs to capture SageMaker logs and CloudTrail to track API calls. Implement centralized log aggregation for security analysis.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Detection and response"],
    "relatedIds": ["SEC04-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC04-BP02",
    "title_full": "MLSEC04-BP02 Monitor for anomalous ML behavior and unauthorized access",
    "title": "Monitor for anomalous ML behavior and unauthorized access",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-04.html",
    "description": "Implement security monitoring to detect anomalous ML operations such as unusual training job patterns, unexpected model deployments, or suspicious inference traffic. Use Amazon GuardDuty to monitor for threats and CloudWatch Alarms to alert on security-relevant metrics.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Detection and response"],
    "relatedIds": ["SEC04-BP02"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC05-BP01",
    "title_full": "MLSEC05-BP01 Assess and mitigate bias in ML models",
    "title": "Assess and mitigate bias in ML models",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-05.html",
    "description": "Use Amazon SageMaker Clarify to detect bias in training data and model predictions across protected attributes. Implement bias mitigation techniques during data preparation and model training. Establish ongoing bias monitoring for deployed models and document bias assessment results.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Responsible AI"],
    "relatedIds": ["SEC07-BP02"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLSEC05-BP02",
    "title_full": "MLSEC05-BP02 Implement model explainability for transparency and compliance",
    "title": "Implement model explainability for transparency and compliance",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mlsec-05.html",
    "description": "Generate model explanations using Amazon SageMaker Clarify to understand feature importance and prediction reasoning. Provide explainability reports for regulatory compliance and audit requirements. Enable real-time explanations for inference requests in applicable use cases.",
    "outcome": "",
    "pillar": "SECURITY",
    "area": ["Responsible AI"],
    "relatedIds": ["SEC07-BP03"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  }
]
