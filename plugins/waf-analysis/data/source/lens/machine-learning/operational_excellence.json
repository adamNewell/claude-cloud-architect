[
  {
    "id": "MLOE01-BP01",
    "title_full": "MLOE01-BP01 Establish clear business objectives and success metrics for ML workloads",
    "title": "Establish clear business objectives and success metrics for ML workloads",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-01.html",
    "description": "Define measurable business objectives and key performance indicators (KPIs) before starting ML projects. Establish baselines and success criteria to evaluate ML model performance against business goals. Document expected outcomes, acceptance criteria, and how ML solutions will integrate with existing business processes.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Business goal definition"],
    "relatedIds": ["OPS01-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE01-BP02",
    "title_full": "MLOE01-BP02 Define roles and responsibilities for ML teams",
    "title": "Define roles and responsibilities for ML teams",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-01.html",
    "description": "Clearly define roles including data scientists, ML engineers, data engineers, and business stakeholders. Establish ownership for each phase of the ML lifecycle from data preparation through model deployment and monitoring. Create cross-functional teams that combine domain expertise with technical ML skills.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Organization"],
    "relatedIds": ["OPS01-BP02"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE02-BP01",
    "title_full": "MLOE02-BP01 Implement version control for ML artifacts including data, code, and models",
    "title": "Implement version control for ML artifacts including data, code, and models",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-02.html",
    "description": "Use version control systems to track changes to ML code, training data, feature engineering pipelines, model configurations, and trained model artifacts. Implement data versioning strategies using services like Amazon S3 versioning or dedicated ML versioning tools. Maintain lineage between datasets, code versions, and model versions.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["ML lifecycle management"],
    "relatedIds": ["OPS05-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE02-BP02",
    "title_full": "MLOE02-BP02 Automate ML pipelines for reproducible training and deployment",
    "title": "Automate ML pipelines for reproducible training and deployment",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-02.html",
    "description": "Build automated ML pipelines using Amazon SageMaker Pipelines, AWS Step Functions, or similar orchestration tools. Automate data preparation, feature engineering, model training, evaluation, and deployment processes. Ensure pipelines are reproducible and can be triggered on schedule or by events.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["ML lifecycle management"],
    "relatedIds": ["OPS05-BP02"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE02-BP03",
    "title_full": "MLOE02-BP03 Implement experiment tracking and model registry",
    "title": "Implement experiment tracking and model registry",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-02.html",
    "description": "Track ML experiments including hyperparameters, metrics, and artifacts using Amazon SageMaker Experiments or similar tools. Maintain a model registry to catalog trained models with metadata, performance metrics, and approval status. Enable comparison across experiments to identify best-performing configurations.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["ML lifecycle management"],
    "relatedIds": ["OPS05-BP03"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE03-BP01",
    "title_full": "MLOE03-BP01 Establish data quality validation and monitoring processes",
    "title": "Establish data quality validation and monitoring processes",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-03.html",
    "description": "Implement data quality checks at each stage of the ML pipeline including completeness, consistency, accuracy, and timeliness. Use Amazon SageMaker Data Wrangler or AWS Glue DataBrew for data profiling and validation. Set up automated alerts when data quality metrics fall below acceptable thresholds.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Data management"],
    "relatedIds": ["OPS08-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE03-BP02",
    "title_full": "MLOE03-BP02 Document data sources, transformations, and feature engineering logic",
    "title": "Document data sources, transformations, and feature engineering logic",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-03.html",
    "description": "Maintain comprehensive documentation of data sources, schemas, data transformations, and feature engineering pipelines. Use feature stores like Amazon SageMaker Feature Store to centralize feature definitions and ensure consistency between training and inference. Document data lineage to trace features back to source data.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Data management"],
    "relatedIds": ["OPS08-BP02"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE04-BP01",
    "title_full": "MLOE04-BP01 Monitor model performance metrics in production",
    "title": "Monitor model performance metrics in production",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-04.html",
    "description": "Implement continuous monitoring of model predictions and performance metrics using Amazon SageMaker Model Monitor or Amazon CloudWatch. Track metrics like prediction accuracy, latency, throughput, and error rates. Set up dashboards to visualize model health and configure alerts for performance degradation.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Model monitoring"],
    "relatedIds": ["OPS04-BP01"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE04-BP02",
    "title_full": "MLOE04-BP02 Detect and alert on data drift and model drift",
    "title": "Detect and alert on data drift and model drift",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-04.html",
    "description": "Implement drift detection to identify when input data distributions or model predictions change significantly from baseline. Use Amazon SageMaker Model Monitor to automatically detect data drift, concept drift, and feature attribution drift. Configure alerts to trigger model retraining or investigation when drift exceeds thresholds.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Model monitoring"],
    "relatedIds": ["OPS04-BP02"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE04-BP03",
    "title_full": "MLOE04-BP03 Implement logging for model predictions and explanations",
    "title": "Implement logging for model predictions and explanations",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-04.html",
    "description": "Log model inputs, predictions, and confidence scores for debugging and audit purposes. Use Amazon SageMaker Clarify to generate model explanations and feature attributions. Store prediction logs in a format that enables analysis and supports regulatory compliance requirements.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Model monitoring"],
    "relatedIds": ["OPS08-BP03"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE05-BP01",
    "title_full": "MLOE05-BP01 Implement safe deployment strategies for ML models",
    "title": "Implement safe deployment strategies for ML models",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-05.html",
    "description": "Use deployment strategies like canary deployments, blue-green deployments, or shadow deployments to safely roll out new model versions. Configure automatic rollback based on performance metrics. Test new models against production traffic samples before full deployment using Amazon SageMaker deployment guardrails.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Model deployment"],
    "relatedIds": ["OPS05-BP04"],
    "risk": "HIGH",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE05-BP02",
    "title_full": "MLOE05-BP02 Establish model approval and governance workflows",
    "title": "Establish model approval and governance workflows",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-05.html",
    "description": "Implement governance workflows that require human approval before models are promoted to production. Define approval criteria including performance thresholds, bias assessments, and security reviews. Use Amazon SageMaker Model Registry to manage model approval status and track deployments across environments.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Model deployment"],
    "relatedIds": ["OPS05-BP05"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  },
  {
    "id": "MLOE06-BP01",
    "title_full": "MLOE06-BP01 Establish processes for continuous model improvement and retraining",
    "title": "Establish processes for continuous model improvement and retraining",
    "href": "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/mloe-06.html",
    "description": "Define triggers and schedules for model retraining based on performance degradation, data drift, or new data availability. Automate the retraining pipeline to incorporate new data and techniques. Maintain historical model performance records to track improvements over time.",
    "outcome": "",
    "pillar": "OPERATIONAL_EXCELLENCE",
    "area": ["Continuous improvement"],
    "relatedIds": ["OPS11-BP01"],
    "risk": "MEDIUM",
    "lens": "MACHINE_LEARNING"
  }
]
